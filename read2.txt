 Let's now check out the difference between static and dynamic rendering in practice by analyzing how the different routes in or out are actually rendered by Next.js. So, remember from the previous lecture that it's basically Next.js who decides how each of our routes are rendered. So whether each of the routes is going to be a dynamic route or a static route. Now to see how each route is actually rendered, we need to build the site, basically using the built command that Next.js provides to us. So we can check that out here in packag.json and so this is the one we've been using so far, but there's also the build command. So let's finish or quit what we have here and then instead run NPM, run, build. Now before you actually run this, maybe you want to take a minute and try to analyze this by yourself and trying to figure out how each route is gonna be rendered without checking these results. So that would be a good exercise of reviewing the previous lecture, but I'm just gonna run the command here. This is probably gonna take a little bit of time. We should also get some warnings here, but actually no. Let's see. Let's make this bigger, actually. Let's give ourselves some more space and so here is where we run that command. So we get all the ESLint warnings here, so some images that we should convert to the image component and then here we have a list of all of the routes in our page and then down here we can see that the ones with the small circle here are statically rendered. So remember that static is the same, basically, as pre-rendered as static content and then these ones with the Lambda here, they are dynamic routes, so they are server side-rendered on demand. So, right now, all of the routes here except this one here are static. Now, why is this one here a dynamic route? Can you guess why that is? Well, the answer is that it has this dynamic segment, so this cabin ID cannot be known by Next.js at build time. So Next.js doesn't know which possible IDs the user could visit on our page. So right here. Well, now we can actually not reach the site anymore because we quit the process there, but you get the point. Like Next.js has no way of pre-rendering this page, so it doesn't know that maybe this here could be a possible ID, so therefore it will not run this URL here and pre-render the HTML aesthetic content, right? I mean, there is a way in which we can tell it which IDs might actually exist and we're gonna do that in the next lecture, but for now, there is no way in which, again, Next.js can know all the possible IDs that it could then replace here in the URL and then pre-render. All right? And so that's why Next.js selects, again, this route with the dynamic segment as being a dynamic route, okay? And we have no other one because we're not using cookies yet or we're not using any headers or any search paras until now. So we're gonna use some of these things later and so by then we can actually run this again to check out how our routes look like then, so to see how they're gonna be rendered in those scenarios, but for now, it's just very simple, but I just wanted to show you that this is how we can exactly analyze that, but in practice, you don't need to worry too much about this because when you deploy the app to Vercel, for example, all of this stuff will just happen automatically and behind the scenes. Now, all right? Now, as I just hinted at earlier, there is actually a way of telling Next.js about all the possible IDs here and so let's move on to the next video and see exactly how we can do that. Let's see how we can use the generateStaticParams function to let Next.js know about all the possible values of a dynamic URL segment so that we can then export those pages as static pages. So as we just learned in the previous lecture, Next.js will render the pages that correspond to this dynamic URL here in a dynamic way, because again, it has no way of knowing these different cabin IDs here beforehand, so at build time. So therefore, each of these pages needs to be built at request time. So a new for each new incoming request. But let's actually run the page again. So npm run dev so that we can look at the page again. Now, if we run this one here, then we should probably get that this cabin should not be found, right? Now the thing is that we only have like eight cabins, right? So we only really care about eight different IDs. So this 89 right here, then here we have 90 and so on all the way to this 96. So for you, those IDs are probably different, but what matters is that we only care about these eight IDs. And so in a way, we developers actually know which IDs we care about, so we know them beforehand. All we have to do now is to tell Next.js about these eight IDs basically. And then if Next.js knows that it should only pre-render this page here with eight different IDs, then it can do that. Or in other words, if we tell Next.js about the possible set of IDs that this dynamic segment here can take here, then Next.js will be able to render those eight pages as static pages as well. And so then all our pages will be static and we could then export or we could generate the entire site as a static site and deploy it very easily on any static hosting provider that we want. So long story short, let's just do what I just said. So what we need to do is to export yet another function that Next.js gives us. Or actually a function name, which Next.js will then recognize. And that function is called generateStaticParams. And again, this is all about telling Next.js ahead of time, which params actually exist here for this page. So for this dynamic route. So the way we do that is of course not by manually writing here, 89, 90, 91, and so on, but instead, we need to actually get those because again, for you, they might be different and they might even change in the future. So maybe at some point we have like 20 cabins, and then all of those 20 pages should be statically pre-generated. And so basically what we're gonna do is to fetch the cabins and then read the IDs from there. So that's gonna be cabins, await get cabin, or actually that's get cabins. So we want all of them here. So this will give us all of the cabins. So there's no need to lock that here to the console because we already know that this will be an array of objects and each of those objects will have an ID. And so let's just loop over that with a map. And then from here, we need to return an object with the cabin ID property. So let's do that. So cabin ID will be equal to cabin.ID. Okay, let's just store that here in the variable so that we can see it, just so it makes a bit more sense. Let's store this. So let's save that and then we get some error here because we actually need to return something from here, otherwise that's just not gonna work. So we're gonna return that. Still get an error. So let's just log this to the console here. And so here we get that array and this actually looks correct. So let's read. Okay, so all we had to do was actually read here. So the required parameter cabin ID was not provided as a string. So here we need to just convert this to a string. So this is right now a number, but it needs to be a string. Okay. And there we go. Let's just check out our logs again, just so you can understand exactly what we need to return so that you can do this yourself in the future. So basically we need to return here an array, and then for each of the value, in this case of the cabin id, we need to return an object which has that name. So basically the name of the dynamic segment, which here is cabin ID simply because that's the name of the folder. This one right here. So that's cabin ID. That's also what we get from the params prop here. So params.cabinId. And so that's the reason why we need to then return here, an object with the property of cabin id and then with the corresponding value. And so it's these eight IDs for which we want to pre-render a static page. All right. Now here, this is not gonna be very different, so it's gonna work just very similarly. But if we now, and first of all, let's remove this right here. So if we quit this here and then run, npm run build again, so to again see how our routes are actually rendered, then that should look different than what we had before. And already we see that, Now we have 18 pages. So before there it set that we had just 10 pages I remember, and now it's 18. And so notice how here we have the circle again. So this one here now says pre-rendered as static HTML. It uses get static props, which is not really the case. I guess that's still coming from the old pages router. So actually, we used generate static params, but what matters here is that now all of our routes are pre-rendered. So we have no dynamic routes here anymore. So if in your own applications, you ever have a finite set of values for a dynamic segment of a URL, it's always a good idea to tell Next.js about those by using degenerate static params function. Because again, this way, this route can then be entirely statically generated, which is a lot better for performance. So in this case, since all of our routes are now static, we can actually do static site generation. And so let me show you how we can do that in the next video. so now that our website is completely static, let's actually export it as a static site through a process called static site generation so that we could then very, very easily deploy it to any hosting provider that supports static sites, which is basically every hosting provider out there, so the way we do static site generation is actually with the exact same command as before, so we still do npm run build, however, don't run that yet because first we need to change something in the next config file, so here we now need to specify output and set it to export, so that's because basically by doing this, our site will kind of get exported completely as static assets that we can deploy anywhere. All right, and this will then create a brand-new folder even here, which is called out, and we could also change that, for example, to a more common folder name like dist, but out also works just fine, so here, again, we see what we already had earlier so that all the pages are indeed statically rendered. Now, if you would attempt to do this while you actually had some dynamic routes, for example because you didn't use generate static params whenever that's possible, like here, so here we used generate static params, but if we didn't do this, or maybe if we did use cookies or really if there was any reason that made any of the static routes switch to dynamic rendering, then we would get an error while attempting to do this, all right? But since, again, our entire site is already static, we got no problem, and so we then got this out folder. Now, let's actually click here on Reveal in Finder or maybe on Windows that's Reveal in Explorer, but in any case, what I want to do is to just navigate in the file system to this folder right here, so it is this folder that you would now take and just deploy it to any hosting provider out there, so usually deploying a Next.js application is a bit complicated if you do not use Vercel, which we're going to do by the end of the course, by the way, but for static deployment, like what we have here, like, it's really easy. You can place this on GitHub pages or on Netlify, on render.com, or really, all these other services out there. All you have to do is to just basically drag and drop the folder on there, and it would then work, again, because there is no server side code anywhere here now. It's all static assets. Now, we can actually not just run this index.html, so if I just double-click this, then we get something, but it doesn't really work, so let me actually close this here, and what I'm gonna do is to also open this here as a separate VS Code window because I have this Go Live extension here, so let me show that to you, so that's basically, yeah, this live server here, so this is one of the most popular extensions out there, so if you also have that, then this will basically just create a static server for you, and so if you then click there in Go Live, then here is our website, so we can click around, and all the pages are there except for the images, but more about that in a second, but what matters is that all the links still work, and we actually still get that single-page application feeling, and so that's because Next.js actually ships some code which makes all of this work here in the background, and actually, in order for this to work, notice how we have these text files here also for each of the HTML files, so if we open that one up, then what we have is actually a real React Server Components payload, so an RSC payload, so this is kind of the first time we're looking at some real RSC payload, so notice, though, here we have some link to a chunk, so to a part of the bundle, here another one, then here we have some actual content in the form that looks very similar to a React element, and yeah, so you can now really go ahead and analyze this if you want it and compare it maybe again to what we learned in the lecture about how React Server Components work, but this is just what's necessary for Next.js to implement the client side navigation, so that makes it feel like we are still on a single-page application, so all that code here is in this _next folder, so you can just check that out. Here is some of the JavaScript. Yeah, if you have the time or if you feel curious, you can check out all these files, even the CSS, so everything that is provided to you by Next.js, so all of this has been bundled up nicely so that it just works, but speaking of working, what actually doesn't work are our images, unfortunately, and to be more precise, actually, what doesn't work is all the images that we optimized using the image component. so Next.js's image component that we used earlier, and the reason for that is because these images that we optimized were optimized behind the scenes by Vercel on the Vercel server using their own image optimization API, so that optimization basically happens dynamically on a server, which we now no longer have, so therefore, we cannot use this Vercel service anymore, so we could fix this here in two ways. First, we can choose to not optimize image at all, and so then, in our code, we would just go back to, well, to defining the images in the usual way, so just like this, so that would be one option, but the other option would be to create our own custom loader that will then use a different service, for example, Cloudinary, so just Cloudinary, so that's an image optimization service, this one right here, and so we could write a simple loader which will then make our website work again simply by optimizing the images with this service or some other one. Now, that's a bit complex, but I will add a link to that in the resources of this part 5, so there's some lecture at the beginning of part 5, and there I always place some important links, and one of them is about this, so you can also read about that in the documentation, so if you just google next.js static export, then you will also learn what needs to be in the App Router, so then here you can also learn about that a bit better, so of course, server components are supported, and yeah, so here it talks about using a different loader for images, and with an example for Cloudinary. Okay, but that is all we wanted to do here for now, so let's just close that. Go back here, and then let's just npm run dev again, so we're done with this static site generation with this deployment stuff and also with analyzing our different types of rendering. All we have to do next is to quickly look at the hybrid rendering that I mentioned earlier, which is partial prerendering, so let's quickly do that in the next video. In this lecture, let's talk about a brand new rendering strategy that might completely change the way we think about rendering Next.js applications in the future. So at a certain point, the Next.js team came to the realization that most pages in a website actually don't need to be 100% static or 100% dynamic, but rather a mix between these two. So right now, remember, we know that each route in a Next.js app is either static or dynamic. But what if it doesn't have to be that way? For example, imagine a website that is fully static except for the navigation that displays the name of the currently logged in user. So this website will be 100% dynamically rendered, because that username can only be known at request time. But that's a huge waste, because most of each route, except for that username, could be rendered statically at build time, and be delivered via a CDN, making the page a bit faster. And so this is the problem that partial pre-rendering solves. So essentially partial pre-rendering is a new rendering strategy that combines the best parts of both static and dynamic rendering all in the same route. So it's a middle ground between fully static pages and fully dynamic pages. Now it's called pre-rendering because that's basically the same as static, and partial because the pre-rendering only happens for a part of the page. But to make sense of this, let's see how it works. So as a first step, a fully static, so a pre-rendered page is served as fast as possible from a CDN, whenever a user visits the page. This makes the initial loading super fast, and we call this a shell, because it leaves in some holes for the dynamic content. So in this example, on the right hand side, we have these two sections of the static page, that need some dynamic data. And so those are the holes in the static shell. Now, in the meantime, the server starts rendering the dynamic content, which of course takes a bit longer than just sending the static shell, but as soon as some rendering results are available, the server starts streaming the dynamic parts of the page to the client filling the holes that we had left. As a result, we end up with even faster pages that can mostly be delivered from the edge. So from a CDN, even when there are small dynamically rendered parts on the page, this means that pages are no longer forced to be completely dynamically rendered just because one tiny part of the page depends on the incoming request or an uncashed data request. So in this example, we might have something like 80% static content and only 20% dynamically rendered content, making this a great candidate for partial pre-rendering. Now, how do we actually implement this in our app? Well, partial pre-rendering is actually not available in Next.js yet by the time I'm recording this video. So let me just quickly show you how it's gonna work once this feature really ships in the future. So as I just said, as of Next.js version 14, partial pre-rendering or PPR for short is not really usable and should not be used in production right now. However, in the future, in some next version, if you want to use partial pre-rendering, you'll probably have to turn it on in the Next.js config file. So this is an opt-in feature. Now remember how static rendering is the default rendering mechanism in Next.js, and therefore when PPR is enabled, Next.js will still try to statically render as much of each route as possible. And this statically rendered parts will then become the static shell that we talked about earlier. However, some parts of the route might be dynamic. For example, a component that uses the cookies function. Before partial pre-rendering, this would then make the entire route dynamic. But with partial pre-rendering, we can just place that dynamic component into a suspense boundary. So this feature actually leverages a react API that we already know, and so we don't need to learn any new APIs in order to use partial pre-rendering, which is great of course. Again, because we simply use a suspense to tell Next.js that whatever is inside the suspense. So within that boundary is dynamic, and should be therefore dynamically rendered. So basically this is how we define those holes that we talked about earlier. And it makes sense to use a boundary in the form of suspense because it basically prevents the dynamic part, such as reading a header or making a non-cached fetch request from spreading onto the rest of the route, which would make the entire route dynamic, which we might not want. So essentially the suspense boundary isolates the dynamic components or sub trees that will be dynamically rendered. Now, while that dynamic part is rendering, we can provide a static fallback that will be rendered immediately by passing it to the suspense component. Then once the rendering is done, each dynamic part will simply be inserted into the static shell replacing that suspense fallback that we had specified initially. And so that's how you will use partial pre-rendering once it becomes stable and available in Next.js, it's just placing dynamic components into suspenses. So a pretty straightforward to use feature, but one that will really improve performance even further. So make sure to check out the documentation in order to see if this feature might be available for you, and also to learn more details on how to use it in practice. Let's not dive into probably the most confusing part of the Next.js app router, which is caching. But first of all, what actually is caching in the context of a web application? Well, caching essentially means taking data that has been fetched or computed and storing it in a temporary location for future access. This way, when we need the same data again in the future, we can just take it from the cache instead of re fetching or recomputing it every time the data is needed again. Now, in Next.js, caching is very aggressive, both on the server and the user's browser. Basically, everything that can be cached will be cached by Next.js, such as fetch data, visited routes, and so on. Now, besides taking care of caching, Next.js also provides APIs to revalidate the different caches. And revalidating is simply to remove all data from a cache and update it with fresh data. So fetching or computing fresh data again based on the original source. So the idea behind caching is that it makes apps not only more performant with faster page loads, but it also saves computing and data access costs. So imagine you have your data in some content management system and you pay each time that you access data using an API. So if caching allows you to fetch the data way less often, you might end up paying a lot less for data access. So caching can definitely be a huge advantage. The problem is the very aggressive caching that I mentioned earlier, which means that caching is always on by default in Next.js apps, at least in the app router. This can lead to some strange and unexpected behaviors like the page displaying stale data on the client, so data that hasn't been updated. And if you add the fact that some caches can't even be turned off, it becomes very annoying to work with this cache. And in fact, this caching behavior is by far the most criticized aspect of Next.js. Many developers really hate the way that it works. Now, if we do want to control how Next.js caches data, we're in for a hard and confusing time, because there are so many different Next.js APIs that affect and control cache. It can be really difficult to grasp, especially for beginners. But that's where this lecture comes in. So in the reminder of this video, we're gonna take a look at the four different caching mechanisms, compare them with each other and learn how we can control them effectively. So as I just mentioned, there are four different caching mechanisms in Next.js, three of which cache so they store data on the server. Those are called request memorization, data cache, and full route cache. Then on the client, we have the router cache, also known as the client side cache. And so let's not describe what each of these does. So first of all, request memorization is a technique that caches the data that has been fetched with similar get requests during the lifespan of one request by one user. In other words, data is cached and reused only during exactly one page render. This way when a certain route fetches the same data in multiple places in the componentry during one render, only one actual network request will be made. So this cache is a little bit like a short term memory for fetched data. Now, as an example, if we fetched products in five different components, Next.js would only get this data from the API once and not five times. So again, this cache allows us to fetch the same data at multiple places in the tree without making multiple network requests. And this is actually great because this way if we need the same data in five components, we don't have to fetch it all the way at the top of the tree and then pass it down to those five components using props. We can just fetch it everywhere and not worry about multiple requests. Plus, of course, making fewer requests also makes the page faster and might even save costs. Now, this mechanism only works with the native fetch function and when the requests are exactly the same, so with the same URL and options object. Also, this is actually a React feature, and so it only works in the React componentry, not in route handlers or server actions. Next up is the data cache, which stores all the data that has been fetched either in a specific route or from a single fetch request. Now, what's unique about this cache is that the data stays there basically forever unless we decide to revalidate the cache, which remember, means to clear it and re fetch the data. This means that the data is available across multiple requests from different users, and it even survives when the app is redeployed. So if we had, for example, 1 million users requesting the same data over time, Next.js would only have made one fetch request. So every user would get the exact same data. And this sounds a lot like static pages, right? Where every user gets the exact same page. Well, that's because it's this data that actually feeds into static pages, or in other words, it's this data that is used to statically render routes. Now, when this data is revalidated, the corresponding static page will simply be regenerated, and this is the whole idea behind ISR or incremental static regeneration that we talked about earlier. So it's this cache mechanism and then revalidating it that makes this feature possible. So this is actually also a great cache. It really boosts performance as it prevents so many network requests to the original data source. It's also by far the most important one to think about for US developers because it's very configurable, meaning that it's also the most confusing one as we'll see in the next slide. But anyway, next we have the related full route cache. This one stores the entire static pages in the form of HTML and RSC payload at bill time. And as we already learned, static pages only have to be built once and can then be served to multiple users. So this cache is what enables static pages to work the way they do, basically acting as a storing mechanism for these static routes. So again, conceptually, the full route cache is nothing more than building static routes and storing them as HTML and RSC payload. And since this cache is so related to the data cache, the full route cache is persisted until the data cache is invalidated. So until the data cache is cleared, basically, and this makes sense, right? Because if the underlying data changes, then the page needs to be regenerated and stored in the cache again in order to reflect the latest data. Now, unlike the data cache, this one does not survive redeploys. So it will be cleared when you deploy a new version of the application. Now, okay, now remember that all these caches we talked about are stored on the server, but now let's move on to the client and to the router cache. So this cache is used to store right in the browser, all the pre fetched pages, as well as all pages that the user visits while navigating around the application. This applies to both static and dynamic routes because the browser doesn't care about how the route was generated at all. It doesn't even know about that. Now, the idea behind this cache is that having all the pages stored in memory allows for instant or almost instant navigations, which gives the user the feel of a true single page application with no hard reloads. Now, the problem with this cache is the fact that pages are not requested from the server again, as the user navigates back and forth, which can lead to stale data being displayed. In fact, pages are stored for 30 seconds if they are dynamic and for five minutes if they're a static with no way of revalidating this cache. So of updating these cached pages. So unless the user performs a hard reload or closes and reopens the tab, we run into the possibility of rendering outdated data. And that's, in my opinion, the biggest problem with the Next.js cache system. Now, just as a heads up, this is how caching works in production, so in our deployed apps, but not during development. So in development, there is almost no caching happening whatsoever, so that we always see fresh data while building or apps. Okay, so at this point, we should have a pretty good overview of what each of these caches are, what they do, and why they exist. And so next, let's check out how we can configure each cache, or in other words, how we can revalidate each cache and how we can opt out. Starting with request memorization, there is no way of revalidating it because this concept doesn't really apply here. Memorization happens only over the lifespan of a single page render. So the data isn't even persisted anywhere, and so we can't revalidate it. Now, in order to opt out, we can use an abort controller with the fetch function. Now, I'm not showing the whole syntax here because this is generally not needed, but if for some reason you do need to opt out, you can just check out the documentation. Next up, let's move on to the most important one, which is the data cache. So we can set the data cache to be automatically revalidated after a certain amount of time has passed. We can do so for all the data on a certain page by exporting a revalidate cons from page.js, set to a number of seconds after which the cache should be cleared and the data be re fetched. Alternatively, we can revalidate only the result of a certain fetch request by using this API. So that's time-based revalidation, but there is also on demand revalidation where we can manually call the revalidate path or revalidate tech function in order to revalidate the cache on a certain path or with a certain tech. Now, as we learned previously, the full route cache is persisted until the data cache is revalidate. So this means that revalidating the data cache will of course also revalidate the full route cache. And again, this makes sense because the static pages depend on the cache data. And if that data is no longer fresh, then the pages need to be regenerated in the full route cache again. And remember, this is exactly the concept of incremental static regeneration. Now, if we don't want to cache at all, we can opt the entire page out of the data cache simply by exporting the revalidate const like before in time-based revalidation, but this time set to zero seconds. So revalidating after zero seconds means to always revalidate, which effectively opts the page out of the data cache, it turns the cache off. We can also force the entire page to become dynamic with the dynamic constant, as we've also seen in an earlier lecture. And so this will also turn off the data cache because this cache is only for static data. So these two have basically the same effect, but I think revalidate set to zero makes a bit more sense because it's more explicit. On the other hand, we can also turn off caching for single fetch requests using this API, and also for an individual server component by calling the no store function inside of it. Now, using any of these APIs will force the entire page to become dynamic unless you are using partial pre rendering. But that's a whole different level of complexity. So let's leave that aside here. What matters is that as the page becomes dynamic, the full route cache no longer caches it because this cache is only for static pages. Therefore, just like with revalidation, opting out one cache also opts out the other one as they're closely tied together. And by the way, you don't need to exactly memorize all these different ways right now. You just need to know that they exist. Then you can just come back here or to the documentation to learn all about the exact syntax. So my goal here is actually more to show you that all these different possibilities exist in one central place because the documentation on this is pretty spread out over so many different places, which is really confusing. But anyway, moving on to the router cache now, this one also gets revalidated by manually revalidating the data cache with revalidate path or revalidate tech as long as it's being done in a server action, which we'll learn all about later. And once again, if we think about this, it makes sense that it works this way because if we declare the data in the cache as being old by revalidating it, then the pages that are CED in the user's browser and depend on this data should also be refreshed with the fresh data. There are, however, two more ways of revalidating the router cache, which is forcing a reload with Router.refresh or by setting or deleting a cookie in a server action. Finally, as I mentioned earlier, for some reason it's not possible to opt out of this cache. This, in my opinion, makes no sense at all, and I can't actually imagine that this will change in the future because it's indeed quite problematic. When our users use our app, they expect the data that they see to be always up-to-date, and we can simply not guarantee that because of this cache. If the data on a page is updated by something other than revalidation, so without the cache knowing about this update, we're out of luck. And we actually have a nice example of this with the Wild Oasis app. So in this application, if the underlying data was updated by the Vanilla React app that we built earlier in the course, then the Next.js app that we're building right now would not know about this change. It would have no way of knowing that the data has changed in the background, and it would then use the old data for the duration of the router cache. So 30 seconds if it's a dynamic page and five minutes if it's static. And this is really bad and makes it hard to build truly dynamic experiences. But again, I can't imagine that this will change down the line because it's quite unacceptable. But anyway, dare you have it. This is a pretty great overview of caching in Next.js. Now, if you need even more details than this or want to understand how each of these cache mechanisms operates behind the scenes, make sure to check out the official Next.js docs. It has a lot of nice diagrams that don't make sense to replicate here. The problem again is that the documentation can be quite confusing and hard to understand, which is why I created this important, even if it's pretty long lecture for you. So with this lecture, you'll be more than ready to understand and use caching in practice. And so let's actually go do that and explore this subject in practice. All right, so after that long last lecture, let's now have some fun and try out some of the Next.js caching APIs in practice, focusing on the implementation and the need for incremental static regeneration or ISR for short. However, before we do that, we need to fix this error that maybe you also got by running npm run dev again. So after we did that static site generation in the previous code lecture. So it says here that image optimization is not compatible with this export option here. And so let's just turn this off and if we then reload, this should be back to working. All right, and with this, well, let's go back here. Yeah, let's close this. And so here on the Cabins page is where we're gonna experiment with some caching. Now, remember, how I mentioned in the previous lecture that caching does not work as expected in development mode. So caching is basically completely turned off. And so therefore, we need to simulate a production environment. Luckily for us, that is very easy to do using the build script and then this start script. So basically, by combining these two, so this build here, what it does as we already know, is to just build our application. And then this start command here will start up a production server. So basically allowing us to simulate a production environment. So we can run this basically like this. So by combining npm Run build and npm run start. So this would be one way of doing it, but we can also just write our own script here so we don't have to write all of that all the time. So I like to just call this your prod, which stands for production. And then here we can just write next built instead of writing npm run build because that will simply run this command here anyway. And so we can just directly write that there. And then again, the && next start. And so this will then again, first build the application, and then in the second step, take that build application and run it in a Next.js production server. All right, so let's do npm run prod. And so this, of course, will take a little bit more time. And another downside of this is that, of course, it will not listen for changes in our code. So whenever we do something in our code and want to see it live basically on a production server, we need to quit this process and run it all over again. All right, but now let's see and indeed, it works. Now, to start, we already know that this page here is rendered as a static route. So we can also check that here again. Maybe also remember that from earlier. So again here, this circle there means exactly that. So prerendered as static content. Now, what I want you to do is to go back to your original data source in Supabase and try to change some data there. So for example, here in cabin number one, let's try to change the value here to let's say just 350. So that data is now different, but if we reload the page here, then we still get 250, right? And we can in fact reload this here as many times as we want, but that value is not going to change. So why is that? Is it maybe because of the browser cache? Well, not really. It is actually because of the data cache and therefore, of the full route cache. So again, this page has been statically generated. And so this means that this route here has now been cached with this data. So with the data that was in place when the page was statically generated. So basically at that point in time, all the data from our website was set in stone and will now be used for all the users who will visit our page until we revalidate that data. Now, that is great for something where the content is really static, for example, like a blog or something like that, like a marketing page or so. However, here we have kind of a data-intensive application or website. And so that's actually not ideal, right? And so let's actually first try to opt out of the data cache, which will automatically also opt out of the full route cache. So what this means is that we will make this route here dynamic again. So we're gonna force it to become dynamic and remember how there were two possibilities of doing that, but we're gonna go with the one that makes more sense, which is to set the revalidate of this route to zero, so to zero seconds, which means that the data will always be revalidated, which effectively makes this page here dynamic. So we do that by exporting the const revalidate = 0. All right, let's put that here first actually. And just one important thing is that this value here, whatever it is, cannot be computed. So it needs to be really a value. You cannot first have some variable like this, for example, and then do here five times 12. So that's not accepted. It really needs to be some value here. All right. Now, as I mentioned, we now need to quit this process and run it each time we want to see the changes, but in practice, of course, when we're building our apps, we're not always gonna do this. So this is really just to understand how caching works and the difference between these different APIs. But anyway, now we see that our page, so this /cabins route is indeed rendered dynamically. And so now we should get that 350. All right, now let's see what happens if we change this to something else. So let's go back and indeed, there we have our value of 400. We change this again, then you can probably guess what's gonna happen. And indeed, now it is 200. And that makes sense because again, this page is now regenerated for each request, and therefore, it's always getting the fresh data out of the database. And we can perfectly imagine why that is not always ideal in all circumstances. And so again, that's the reason why static rendering is actually the default in Next.js, because then we don't always have to go to the database when the data doesn't need to be queried so often. So if the data almost never changes, then there is no need for a dynamic page. Now, in many situations, what we actually need is kind of a middle ground between these two strategies. So between completely static rendering and dynamic rendering. So the prices of these cabins, they will probably change from time to time. And so a purely dynamic approach where this data is never gonna change is not the right approach in this scenario. On the other hand, the price will probably not change every minute or every hour or even every day or every week. And so it also doesn't make a lot of sense to regenerate this page for every single request, which means making a network trip to the Supabase API for every single user and every single request. So again, what we need is some kind of middle ground. And so that's where incremental static regeneration comes into play. So incremental static regeneration will regenerate a static page and fetch fresh data for it from time to time. And we can simply define that time using this revalidate value right here. So incremental static regeneration sounds like a pretty complex and scary topic, but all we have to do is to export the revalidate const here, set to some number, and then Next.js will automatically refetch the data after the number of seconds that we specify here and swap that data out. And so cache it in the data cache again and regenerate the static pages as well. So again, it's kind of a middle ground between fully static and dynamic. Now, the value that we specify here will depend on how often this data changes. So let's assume that maybe these prices here or even some other data in any of these cabins changes every day. So like once per day. Probably it's not gonna be that much, but let's just assume once per day. And so I think a sensitive approach to refetching the data would be once per hour. We could also do once per minute so that we get really sure that all the users always get the fresh data, but maybe that's not worth it. So maybe once per hour, at least here in this overview page is enough. Maybe on the individual pages we could refetch the data more often so that when the user wants to really book the cabin, then they really always get the freshest data. But here we're just worrying about the overview. And so let's just do once per hour. So that's 60 times 60, which is 3,600 seconds. So again, it needs to be always in seconds. So this is the value that would make sense for us. But since here, we want to experiment, let's do like every 15 seconds. So let's go with that here. Let's quit and rerun again. Okay, let's wait for it. Okay, so 250. Now let's change it here. Well, actually why is that? This is not cabin. Ah, I mean here, let's make this a bit bigger. I mean, cabin one is 200. All right, so here we get to 200. I guess that was the change that we made earlier. So let's just reload here once again. Then let's change it here to 500, let's say. And as we reload now, we won't get that change immediately. So we're still at 200, but at some point, the 15 seconds will have passed. And then indeed, we get the $500 that we specified in Supabase earlier. And if you want to see the effect a bit better, you can maybe try with like with one minute or so. Then you can really be sure. So let's just reload here once again. I will now change this to 200 again. And once again, we don't get that value immediately. So for some time, the page is still static. And so that's exactly the middle ground that we want. And this is of course especially important for pages that get a lot of traffic. So all the traffic in the meantime, so during that time where the data is still cached, doesn't have to come from the database and is instead basically read from the data cache and full route cache. Anyway, if we do this now again, so the 15 seconds have passed, and so now we still get 500. And so that's because the first user who basically comes to the page after that time has passed is the one who will regenerate it for the next one. And so if you do that now again, then that value will have been read in. So again, it is actually the next visitor who checks out the page after the time has passed who will regenerate the page in the background, but it's only then the subsequent user who will get that new result. All right, but that's no big deal because usually many users are visiting our page at the same time. Let me just demonstrate that again, let's do 250. Then let's wait some more time here. And if we then reload this here, like really fast two times, then it is the second user basically that we simulate that will get the new fresh data. So do it now once and immediately again. And there it is. Beautiful. So this is really a great tool that you should use if your data is like this. So data that changes from time to time but not constantly. And so then according to the frequency of change, you should then set this revalidate const right here. Now, right? But now let's just keep going with testing some revalidation and now at the component level. So all of this here is at the route level, but we can also use revalidation at the component level or at the individual fetch level. So let's opt or comment out this here. Let's go to the CabinList because this is the one that is actually fetching the data. Now, if we wanted to revalidate this fetch request right here, this would actually not work right now because we are using the Supabase library here in the background and not really the Fetch API. So that wouldn't be really easy to do 'cause as we learned in the previous lecture, for doing that, we need to pass in the revalidate time right into the fetch function. So we cannot do that. But what we can do is to opt out of caching for this component. And for doing that, we use the Next.js noStore function. Let's import that here. And right now that function is actually called unstable, unstable_noStore, like this, but let's change it to just noStore. And at some point in the future, this will then probably be the official name. From next/cache. And then let's call it here at the very beginning of the function. Now, all right, okay, so here now these two are not active and so if this here wouldn't exist, then now our page would be back to static rendering. But now let's check out what actually happens here because now we have a component here on this page which has a non-cached data request basically. And so as we learned also in one of the lectures, that then makes the entire page rendered dynamically again. And so we can check that out here. Let's change the price again, let's say 400 this time. And so immediately, we will then get that new price right here. So in practice right now, opting out one of the components of the page out of the data cache. So basically telling that it should not cache any data will opt out the entire route out of the data cache because it will dynamically generate this entire route itself. So why should we ever do this here instead of just always revalidating the entire route? Well, right now, as I just mentioned, this makes no difference. But if we think about partial prerendering, it actually makes a lot of sense. So in that scenario, so within partial prerendering, this entire shell of the page would still be static. So like all of this and this, but then here, this CabinList, since it's already wrapped in a suspense, would then become the dynamic whole, which would be rendered in the background, and then be streamed in as soon as it's ready while this fallback would be rendered in the beginning. All right, so remember that that's how partial prerendering works. So again, in that case, in the future, which we are already preparing for here in a way, only this part here would then become dynamic, again because by doing this, just this component opts out of the data cache. So it's an uncached data fetching. And so yeah, then the rest of the page would still be static, which we call the static shell. And then only this here would be the dynamic whole. So basically, it's a bit thinking ahead, thinking about the future with partial prerendering. Alright, so we're mixing a lot of topics here, but well, as I said, this is a pretty confusing topic indeed. Let's just comment out this one here again, and let's put this one here on because at this point, we're basically ready with all this revalidation stuff. Now, notice how we only talked about time-based revalidation, but there is also on demand. So manual revalidation, remember? So that's with revalidate path and revalidate tag, but these only make sense in server actions, which we're gonna learn about later. And so that's when we're gonna talk and use those ones in practice. Now, all right, and let's finish off here because this is already confusing enough, I guess. So the way that caching works together with the way caching affects whether a route is rendered in a static or in a dynamic way is really by far the most confusing thing about Next.js. But at the same time, it's also super important to understand how all of this works together and how it interacts with one another. So these two topics of caching and of dynamic versus static rendering are really, really tied together in Next.js and so you need to understand how it all works. Now, I guess the only thing that you can do is to experiment around with this as much as you can and build as many apps as you can if you have the time because if you do that, you're gonna come across so many different scenarios that are gonna teach you how caching affects your application and therefore, how this all works. And as you do that, of course, you can keep checking out the previous lecture and maybe also rewatch this one. Now, okay. And now, before we close off this section, let's just very quickly practice some things that we learned in this section. So very quickly, what I want you to do is here in the About page, to basically fetch the number of cabins that is displayed here. So right now, in our About page, so right here, we have this number 8 actually hardcoded, but if ever any cabins are added to this hotel, then this number will be out-of-date, and so therefore it should of course be fetched dynamically. All right, and so, just replace that here with the actual number of cabins, which is still actually 8, but now that number 8 will be fetched from the database. Now this number of cabins will probably almost never change, but it might still change at some point in the future. And so, just like before, this shouldn't be a 100% statically-rendered page where the data never changes. So instead, configure this route so that the data is gonna be refetched once per day. So I think that's a good amount of time, all right? So, pause the video here, take a few minutes, and then I'll see you back here very soon. All right, now first of all, let's go back here actually and remove this random number. Then here, we also need to quit this process right here and go back to npm run dev. All right, but now moving on here. All right, so this was indeed an extremely simple challenge, but I just wanted to practice a little bit some of these simple concepts, so, like fetching data, using async/await in a server component. So let's call this, cabins, and then we can await getCabins, all of them. Then we make this an async function, of course, and then here we just replace this hard-coded number with cabins.length. So that's pretty simple. And of course we still will see that number 8 there, because indeed that's the number of cabins that we have. So that was one part, and now let's export the revalidate const, and set to something other than zero, because, remember, that will then refetch the data in the data cache and also in the full route cache whatever number of seconds that we place here. So I said once per day, and so that's 86,400 seconds if you did the math. And that's it. This is all we had to do in this challenge. And again, we're no longer in that production mode, so we are not gonna be able to see that here. And, well, one day... it's actually too much to write here anyway. But, yeah, this is going to work, and it will ensure that this data here, so that the information on this page, stays correct over time. Now, all right, and with this, we actually finish this section off, and so hopefully I see you soon in the next one.

